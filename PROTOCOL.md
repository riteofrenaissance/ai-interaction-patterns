📋 Study Protocol

AI Interaction Patterns: A Study of Psychological Predictors and Outcomes in AI-Mediated Self-Reflection

Study Title: AI Interaction Patterns: A Study of Psychological Predictors and Outcomes in AI-Mediated Self-Reflection

Principal Investigator: Samir Baladi
Affiliation: Rite of Renaissance
Protocol Version: 1.0
Date: April 2026
Status: Pre-registration (awaiting completion of Safe Aperture Study)

---

📚 Abstract

Background: Users increasingly turn to AI conversational agents (e.g., ChatGPT, Claude, Copilot, DeepSeek) for self-reflection, seeking moments of insight, clarity, or self-understanding. However, the outcome of these interactions varies widely: some users experience profound self-awareness, others feel frustrated or misunderstood, and still others become entrapped in illusions of control without genuine insight.

Objective: To investigate how user intentionality (N), structural awareness (W), contemplative patience (S), and interaction depth (M) predict three distinct outcomes (R): reaching insight, experiencing frustration, or falling into the illusion of control.

Design: Cross-sectional observational study with pre-interaction surveys, logged AI conversations, and post-interaction outcome assessment.

Sample: N = 120 adults who use AI for self-reflective purposes.

Measures: Custom scales for N/W/S, behavioral logs for M, and outcome classification for R.

Analysis: Multinomial logistic regression and latent profile analysis to model R = f(N, W, S, M).

Expected Contribution: First empirical investigation of the psychological predictors and outcomes of AI-mediated self-discovery.

---

🎯 Research Questions & Hypotheses

Primary Research Question:

"How do user intentionality (N), structural awareness (W), contemplative patience (S), and interaction depth (M) interact to determine the outcome (R) of AI-mediated self-reflection?"

---

Theoretical Model:

```
R = f(N, W, S, M)

Where:
N = Intention Quality (clarity, authenticity, depth-seeking)
W = Structural Awareness (critical understanding of AI limitations)
S = Contemplative Patience (ability to stay with questions)
M = Interaction Depth (behavioral engagement metrics)
R = Outcome (Insight / Frustration / Illusion)
```

---

Hypotheses:

H1 (Insight Path):
High N + High W + High S → R = Insight (clarity, self-understanding)

H2 (Illusion Path):
Low N + Low W + Low S + High M → R = Illusion (dependency, false sense of control)

H3 (Frustration Path):
Moderate N + Low W + Low S → R = Frustration (disappointment, feeling misunderstood)

H4 (Interaction Depth as Moderator):
M moderates the relationship between N/W/S and R (deeper engagement amplifies effects)

H5 (Profile-Based):
Distinct user profiles emerge based on N/W/S combinations, each predicting specific outcomes

---

🔬 Study Design

Design Type:

Cross-sectional observational study with mixed methods (quantitative surveys + qualitative interaction logs)

Timeline:

· Protocol finalization: May 2026
· IRB approval: June 2026
· Recruitment: July-August 2026 (6 weeks)
· Data collection: July-September 2026 (8 weeks)
· Analysis: October-November 2026
· Results dissemination: December 2026

Sample Size:

Target N = 120 participants

Power Analysis:

· Multinomial logistic regression with 3 outcomes, 4 predictors
· Effect size: OR = 2.0 (medium)
· Power: 80%
· Alpha: 0.05
· Required N ≈ 110-120 (accounting for 10% incomplete data)

---

👥 Participants

Inclusion Criteria:

· Age ≥ 18 years
· Regular AI user (at least 2x/week for past month)
· Uses AI for self-reflective purposes (not just information retrieval)
· English proficiency
· Willing to share anonymized conversation log from one session

Exclusion Criteria:

· Professional AI researchers or developers (insider knowledge may confound W)
· Current severe mental health crisis (assessed via brief screener)
· Unable to complete online procedures

Recruitment:

· Online platforms: Reddit (r/ChatGPT, r/ClaudeAI), Twitter/X, AI user forums
· Prolific Academic (paid participants, $15 for ~45 minutes)
· Snowball sampling from initial participants
· Target demographics: diverse age, gender, education (stratified sampling)

---

📏 Measures

Pre-Interaction Surveys:

1. AI Intentionality Scale (N) - Custom

Construct: Intention Quality
Dimensions:

· Clarity: "I know exactly what I seek when using AI"
· Authenticity: "I am honest with myself in my questions to AI"
· Depth-seeking: "I use AI to explore deep questions about myself"

Format: 12 items, 5-point Likert (1 = Strongly Disagree, 5 = Strongly Agree)
Scoring: Mean of items (range 1-5)
Development: Pilot tested with N=30, validated for this study

Example Items:

· "When I talk to AI, I have a clear sense of what I'm searching for"
· "I ask AI questions that genuinely matter to me"
· "I use AI to understand myself better, not just to get information"

---

2. AI Structural Awareness Scale (W) - Custom

Construct: Critical understanding of AI's nature and limitations
Dimensions:

· Ontological awareness: "AI is a tool, not a being"
· Epistemological awareness: "AI reproduces patterns, not truth"
· Relational awareness: "AI doesn't 'understand' me"

Format: 10 items, 5-point Likert
Scoring: Mean of items (range 1-5)

Example Items:

· "I understand that AI reflects existing knowledge structures, not objective reality"
· "I don't expect AI to truly 'get' my unique situation"
· "I see AI as a mirror for my thinking, not a guide"

---

3. Contemplative Patience Scale (S) - Adapted

Construct: Ability to stay with ambiguity and resist premature closure
Source: Adapted from MAAS (Mindfulness Attention Awareness Scale) + new items

Format: 8 items, 5-point Likert
Scoring: Mean of items (range 1-5)

Example Items:

· "I can sit with a question without needing an immediate answer"
· "I'm comfortable exploring ideas without reaching conclusions"
· "I use AI as a space for reflection, not just problem-solving"

---

4. Demographics & AI Use:

· Age, gender, education
· AI platforms used (ChatGPT, Claude, Copilot, DeepSeek, etc.)
· Frequency of use
· Primary use cases (work, learning, self-reflection, etc.)
· Previous experience with therapy/coaching

---

During Interaction:

5. Behavioral Interaction Logs (M)

Data Collected (from one AI conversation):

· Number of turns (user messages)
· Average message length (characters)
· Conversation duration (minutes)
· Number of follow-up questions
· Complexity metrics (e.g., question depth, sentiment)

Privacy: Users export their own conversation (anonymized), upload to secure platform

Variables Computed:

· M_turns: Total number of user messages
· M_length: Mean message length
· M_duration: Total conversation time
· M_followups: Ratio of follow-up to new questions
· M_complexity: Composite score from linguistic analysis

---

Post-Interaction Survey:

6. Outcome Classification (R)

Three Pathways Assessed:

Insight/Clarity:

· "I gained new understanding about myself"
· "The conversation helped me see things from a new angle"
· "I feel more clarity after this interaction"
· Measured via: Insight Experience Scale (custom, 6 items)

Frustration/Misunderstanding:

· "I felt the AI didn't understand what I was asking"
· "The conversation left me feeling unsatisfied"
· "I had to repeat myself or rephrase often"
· Measured via: AI Interaction Frustration Scale (custom, 5 items)

Illusion/Dependency:

· "I feel like the AI 'gets' me better than people do"
· "I rely on AI to make sense of my thoughts"
· "I feel I'm in control, but I'm not sure what I'm controlling"
· Measured via: AI Dependency & Illusion Scale (custom, 7 items)

Classification Method:

· Continuous scores for each pathway (Insight/Frustration/Illusion)
· Primary outcome = highest scoring pathway
· Secondary: continuous scores for nuanced analysis

---

🔄 Procedure

Step 1: Screening & Consent (5 minutes)

· Online screening questionnaire (eligibility check)
· Informed consent (emphasize voluntary participation, data privacy)
· Participants receive unique ID

Step 2: Pre-Interaction Survey (15 minutes)

· Complete N, W, S scales
· Demographics and AI use background
· Randomization check: ensure representative sample

Step 3: AI Interaction Session (Self-Scheduled)

Instructions:

"In the next 7 days, have ONE conversation with your preferred AI (ChatGPT, Claude, Copilot, DeepSeek, etc.) where you explore a question or topic related to understanding yourself better. This could be about your emotions, decisions, relationships, or any aspect of self-reflection. Try to engage naturally, as you normally would."

Data Collection:

· Participants export their conversation (platform-specific instructions provided)
· Upload anonymized log to secure server (Qualtrics/REDCap)

Step 4: Post-Interaction Survey (10 minutes)

Within 24 hours of AI conversation:

· Complete R outcome measures (Insight/Frustration/Illusion)
· Reflection questions (open-ended):
  · "What were you hoping to find in this conversation?"
  · "How did you feel afterward?"
  · "Did the AI help you in the way you expected?"

Step 5: Debriefing & Compensation

· Thank you message
· Explanation of study purpose
· Mental health resources (if needed)
· Compensation: $15 via Prolific or gift card

---

📊 Data Analysis Plan

Data Preparation:

1. Data Cleaning:

· Check for missing data (exclude if >20% missing on key variables)
· Assess normality and outliers
· Log transformations if needed (e.g., M_duration)

2. Interaction Log Processing:

· Extract behavioral metrics (M_turns, M_length, etc.)
· Sentiment analysis (VADER or similar)
· Complexity scoring (readability indices)

3. Outcome Classification:

· Compute continuous scores for Insight/Frustration/Illusion
· Assign primary outcome (highest score)
· Check distribution (expect ~30-40% per category based on pilot)

---

Primary Analyses:

Analysis 1: Multinomial Logistic Regression

Model:

```r
library(nnet)

model <- multinom(R_outcome ~ N + W + S + M_composite + 
                  N:W + W:S + S:M, 
                  data = data)
```

Primary Test: Effect of N, W, S, M on probability of each outcome (Insight vs Frustration vs Illusion)

Covariates: Age, gender, AI experience (if significant in preliminary checks)

Effect Sizes: Odds ratios (OR) and 95% CIs

---

Analysis 2: Latent Profile Analysis (LPA)

Rationale: Identify naturally occurring user "profiles" based on N/W/S

Model:

```r
library(tidyLPA)

profiles <- estimate_profiles(data[, c("N", "W", "S")], 
                               n_profiles = 2:5)
```

Steps:

1. Determine optimal number of profiles (BIC, entropy)
2. Characterize each profile (e.g., "Critical Skeptic", "Naive Seeker", "Contemplative Explorer")
3. Test: Profile → R outcome (chi-square or multinomial regression)

---

Analysis 3: Moderation Analysis

Test H4: Does M moderate N/W/S → R relationships?

Model:

```r
# Example for M moderating N → R_insight
glm(R_insight ~ N * M_composite + W + S, 
    family = binomial, data = data)
```

Interpretation: Does deeper engagement (high M) amplify benefits of high N/W/S?

---

Secondary Analyses:

1. Qualitative Coding:

· Open-ended responses: thematic analysis
· Identify unexpected pathways or experiences
· Triangulate with quantitative findings

2. Interaction Log Content Analysis:

· What topics do Insight users discuss vs Frustration/Illusion?
· Linguistic differences (e.g., question types, pronoun use)
· AI response patterns (does AI "style" matter?)

3. Exploratory:

· Gender differences in pathways
· Age effects (younger → more Illusion?)
· Platform differences (ChatGPT vs Claude vs Copilot vs DeepSeek)

---

🔒 Ethical Considerations

Informed Consent:

· Participants informed about:
  · Study purpose (understanding AI interaction for self-reflection)
  · Data collected (surveys + anonymized conversation log)
  · Risks (minimal: potential discomfort reflecting on AI interactions)
  · Benefits (contribution to research, self-awareness)
  · Right to withdraw anytime

Privacy & Anonymization:

· Conversation logs: participants remove all identifying information before upload
· Data stored on encrypted servers (Qualtrics/REDCap)
· No IP addresses or identifying metadata collected
· Data de-identified before analysis

Mental Health Safeguards:

· Screener excludes acute mental health crises
· Post-study resources provided (crisis hotlines, therapy directories)
· If participant reports distress → follow-up contact with resources

Deception:

· No deception used
· Full disclosure of study purpose after completion

---

⚠️ Limitations & Anticipated Challenges

1. Self-Selection Bias:

· Users who volunteer may already be more reflective or AI-savvy
· Mitigation: Stratified recruitment, document demographics

2. Self-Report for Outcome:

· R (outcome) is subjective self-report, not objective measure
· Mitigation: Triangulate with qualitative data, use validated scales where possible

3. Single Interaction:

· Only captures one AI conversation, not longitudinal patterns
· Mitigation: Ask about "typical" experience, future studies can track over time

4. Platform Variability:

· Different AIs (ChatGPT, Claude, Copilot, DeepSeek, etc.) may produce different experiences
· Mitigation: Collect platform data, control in analysis if needed

5. Causality:

· Cross-sectional design cannot establish causation (N/W/S → R vs R → N/W/S)
· Mitigation: Pre-post design (N/W/S before, R after) provides temporal ordering

6. Measurement Validity:

· Custom scales (N, W, R) not yet fully validated
· Mitigation: Pilot test, report psychometric properties, revise if needed

---

📚 Theoretical & Practical Contributions

Theoretical:

1. First empirical test of psychological predictors of AI-mediated self-discovery outcomes
2. Integrates mindfulness theory, critical AI literacy, and human-AI interaction research
3. Challenges assumptions that AI is universally beneficial or harmful for self-reflection
4. Proposes R = f(N,W,S,M) as a generalizable framework for AI interaction quality

---

Practical:

1. Informs AI design: How to support insight pathways, prevent illusion
2. User guidance: Develop "best practices" for self-reflective AI use
3. Education: Teach critical AI literacy (W) and contemplative skills (S)
4. Therapeutic applications: Guidelines for AI-assisted self-reflection in clinical contexts

---

📖 References (Key)

Human-AI Interaction:

· Cowan, B. R., et al. (2023). Understanding trust in conversational agents. CHI.
· Sundar, S. S. (2020). Rise of machine agency. Journal of Computer-Mediated Communication.

Critical AI Literacy:

· Long, D., & Magerko, B. (2020). What is AI literacy? CHI.
· Druga, S., et al. (2022). How young children understand AI. IDC.

Mindfulness & Self-Reflection:

· Laukkonen, R. E., et al. (2022). The science of insight. Psychological Bulletin.
· Killingsworth, M. A., & Gilbert, D. T. (2010). A wandering mind is an unhappy mind. Science.

AI for Self-Discovery:

· Pataranutaporn, P., et al. (2021). AI-mediated communication. Extended Abstracts CHI.
· Inkster, B., et al. (2023). Digital mental health. Nature Digital Medicine.

---

📧 Contact & Transparency

Principal Investigator:
Samir Baladi
Email: riteofrenaissance@proton.me

Pre-registration:
[To be registered on OSF before data collection]

Open Science Commitment:

· ✅ Pre-registration (this protocol)
· ✅ Open materials (all scales publicly shared)
· ✅ Open data (de-identified dataset after publication)
· ✅ Open code (R analysis scripts)

---

📝 Version History

Version Date Changes
1.0 April 2026 Initial protocol for pre-registration

---

Document Status: Draft for pre-registration
Next Step: IRB submission (June 2026)
