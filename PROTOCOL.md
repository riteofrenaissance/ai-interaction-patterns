ðŸ“‹ Study Protocol

AI Interaction Patterns: A Study of Psychological Predictors and Outcomes in AI-Mediated Self-Reflection

Study Title: AI Interaction Patterns: A Study of Psychological Predictors and Outcomes in AI-Mediated Self-Reflection

Principal Investigator: Samir Baladi
Affiliation: Rite of Renaissance
Protocol Version: 1.0
Date: April 2026
Status: Pre-registration (awaiting completion of Safe Aperture Study)

---

ðŸ“š Abstract

Background: Users increasingly turn to AI conversational agents (e.g., ChatGPT, Claude, Copilot, DeepSeek) for self-reflection, seeking moments of insight, clarity, or self-understanding. However, the outcome of these interactions varies widely: some users experience profound self-awareness, others feel frustrated or misunderstood, and still others become entrapped in illusions of control without genuine insight.

Objective: To investigate how user intentionality (N), structural awareness (W), contemplative patience (S), and interaction depth (M) predict three distinct outcomes (R): reaching insight, experiencing frustration, or falling into the illusion of control.

Design: Cross-sectional observational study with pre-interaction surveys, logged AI conversations, and post-interaction outcome assessment.

Sample: N = 120 adults who use AI for self-reflective purposes.

Measures: Custom scales for N/W/S, behavioral logs for M, and outcome classification for R.

Analysis: Multinomial logistic regression and latent profile analysis to model R = f(N, W, S, M).

Expected Contribution: First empirical investigation of the psychological predictors and outcomes of AI-mediated self-discovery.

---

ðŸŽ¯ Research Questions & Hypotheses

Primary Research Question:

"How do user intentionality (N), structural awareness (W), contemplative patience (S), and interaction depth (M) interact to determine the outcome (R) of AI-mediated self-reflection?"

---

Theoretical Model:

```
R = f(N, W, S, M)

Where:
N = Intention Quality (clarity, authenticity, depth-seeking)
W = Structural Awareness (critical understanding of AI limitations)
S = Contemplative Patience (ability to stay with questions)
M = Interaction Depth (behavioral engagement metrics)
R = Outcome (Insight / Frustration / Illusion)
```

---

Hypotheses:

H1 (Insight Path):
High N + High W + High S â†’ R = Insight (clarity, self-understanding)

H2 (Illusion Path):
Low N + Low W + Low S + High M â†’ R = Illusion (dependency, false sense of control)

H3 (Frustration Path):
Moderate N + Low W + Low S â†’ R = Frustration (disappointment, feeling misunderstood)

H4 (Interaction Depth as Moderator):
M moderates the relationship between N/W/S and R (deeper engagement amplifies effects)

H5 (Profile-Based):
Distinct user profiles emerge based on N/W/S combinations, each predicting specific outcomes

---

ðŸ”¬ Study Design

Design Type:

Cross-sectional observational study with mixed methods (quantitative surveys + qualitative interaction logs)

Timeline:

Â· Protocol finalization: May 2026
Â· IRB approval: June 2026
Â· Recruitment: July-August 2026 (6 weeks)
Â· Data collection: July-September 2026 (8 weeks)
Â· Analysis: October-November 2026
Â· Results dissemination: December 2026

Sample Size:

Target N = 120 participants

Power Analysis:

Â· Multinomial logistic regression with 3 outcomes, 4 predictors
Â· Effect size: OR = 2.0 (medium)
Â· Power: 80%
Â· Alpha: 0.05
Â· Required N â‰ˆ 110-120 (accounting for 10% incomplete data)

---

ðŸ‘¥ Participants

Inclusion Criteria:

Â· Age â‰¥ 18 years
Â· Regular AI user (at least 2x/week for past month)
Â· Uses AI for self-reflective purposes (not just information retrieval)
Â· English proficiency
Â· Willing to share anonymized conversation log from one session

Exclusion Criteria:

Â· Professional AI researchers or developers (insider knowledge may confound W)
Â· Current severe mental health crisis (assessed via brief screener)
Â· Unable to complete online procedures

Recruitment:

Â· Online platforms: Reddit (r/ChatGPT, r/ClaudeAI), Twitter/X, AI user forums
Â· Prolific Academic (paid participants, $15 for ~45 minutes)
Â· Snowball sampling from initial participants
Â· Target demographics: diverse age, gender, education (stratified sampling)

---

ðŸ“ Measures

Pre-Interaction Surveys:

1. AI Intentionality Scale (N) - Custom

Construct: Intention Quality
Dimensions:

Â· Clarity: "I know exactly what I seek when using AI"
Â· Authenticity: "I am honest with myself in my questions to AI"
Â· Depth-seeking: "I use AI to explore deep questions about myself"

Format: 12 items, 5-point Likert (1 = Strongly Disagree, 5 = Strongly Agree)
Scoring: Mean of items (range 1-5)
Development: Pilot tested with N=30, validated for this study

Example Items:

Â· "When I talk to AI, I have a clear sense of what I'm searching for"
Â· "I ask AI questions that genuinely matter to me"
Â· "I use AI to understand myself better, not just to get information"

---

2. AI Structural Awareness Scale (W) - Custom

Construct: Critical understanding of AI's nature and limitations
Dimensions:

Â· Ontological awareness: "AI is a tool, not a being"
Â· Epistemological awareness: "AI reproduces patterns, not truth"
Â· Relational awareness: "AI doesn't 'understand' me"

Format: 10 items, 5-point Likert
Scoring: Mean of items (range 1-5)

Example Items:

Â· "I understand that AI reflects existing knowledge structures, not objective reality"
Â· "I don't expect AI to truly 'get' my unique situation"
Â· "I see AI as a mirror for my thinking, not a guide"

---

3. Contemplative Patience Scale (S) - Adapted

Construct: Ability to stay with ambiguity and resist premature closure
Source: Adapted from MAAS (Mindfulness Attention Awareness Scale) + new items

Format: 8 items, 5-point Likert
Scoring: Mean of items (range 1-5)

Example Items:

Â· "I can sit with a question without needing an immediate answer"
Â· "I'm comfortable exploring ideas without reaching conclusions"
Â· "I use AI as a space for reflection, not just problem-solving"

---

4. Demographics & AI Use:

Â· Age, gender, education
Â· AI platforms used (ChatGPT, Claude, Copilot, DeepSeek, etc.)
Â· Frequency of use
Â· Primary use cases (work, learning, self-reflection, etc.)
Â· Previous experience with therapy/coaching

---

During Interaction:

5. Behavioral Interaction Logs (M)

Data Collected (from one AI conversation):

Â· Number of turns (user messages)
Â· Average message length (characters)
Â· Conversation duration (minutes)
Â· Number of follow-up questions
Â· Complexity metrics (e.g., question depth, sentiment)

Privacy: Users export their own conversation (anonymized), upload to secure platform

Variables Computed:

Â· M_turns: Total number of user messages
Â· M_length: Mean message length
Â· M_duration: Total conversation time
Â· M_followups: Ratio of follow-up to new questions
Â· M_complexity: Composite score from linguistic analysis

---

Post-Interaction Survey:

6. Outcome Classification (R)

Three Pathways Assessed:

Insight/Clarity:

Â· "I gained new understanding about myself"
Â· "The conversation helped me see things from a new angle"
Â· "I feel more clarity after this interaction"
Â· Measured via: Insight Experience Scale (custom, 6 items)

Frustration/Misunderstanding:

Â· "I felt the AI didn't understand what I was asking"
Â· "The conversation left me feeling unsatisfied"
Â· "I had to repeat myself or rephrase often"
Â· Measured via: AI Interaction Frustration Scale (custom, 5 items)

Illusion/Dependency:

Â· "I feel like the AI 'gets' me better than people do"
Â· "I rely on AI to make sense of my thoughts"
Â· "I feel I'm in control, but I'm not sure what I'm controlling"
Â· Measured via: AI Dependency & Illusion Scale (custom, 7 items)

Classification Method:

Â· Continuous scores for each pathway (Insight/Frustration/Illusion)
Â· Primary outcome = highest scoring pathway
Â· Secondary: continuous scores for nuanced analysis

---

ðŸ”„ Procedure

Step 1: Screening & Consent (5 minutes)

Â· Online screening questionnaire (eligibility check)
Â· Informed consent (emphasize voluntary participation, data privacy)
Â· Participants receive unique ID

Step 2: Pre-Interaction Survey (15 minutes)

Â· Complete N, W, S scales
Â· Demographics and AI use background
Â· Randomization check: ensure representative sample

Step 3: AI Interaction Session (Self-Scheduled)

Instructions:

"In the next 7 days, have ONE conversation with your preferred AI (ChatGPT, Claude, Copilot, DeepSeek, etc.) where you explore a question or topic related to understanding yourself better. This could be about your emotions, decisions, relationships, or any aspect of self-reflection. Try to engage naturally, as you normally would."

Data Collection:

Â· Participants export their conversation (platform-specific instructions provided)
Â· Upload anonymized log to secure server (Qualtrics/REDCap)

Step 4: Post-Interaction Survey (10 minutes)

Within 24 hours of AI conversation:

Â· Complete R outcome measures (Insight/Frustration/Illusion)
Â· Reflection questions (open-ended):
  Â· "What were you hoping to find in this conversation?"
  Â· "How did you feel afterward?"
  Â· "Did the AI help you in the way you expected?"

Step 5: Debriefing & Compensation

Â· Thank you message
Â· Explanation of study purpose
Â· Mental health resources (if needed)
Â· Compensation: $15 via Prolific or gift card

---

ðŸ“Š Data Analysis Plan

Data Preparation:

1. Data Cleaning:

Â· Check for missing data (exclude if >20% missing on key variables)
Â· Assess normality and outliers
Â· Log transformations if needed (e.g., M_duration)

2. Interaction Log Processing:

Â· Extract behavioral metrics (M_turns, M_length, etc.)
Â· Sentiment analysis (VADER or similar)
Â· Complexity scoring (readability indices)

3. Outcome Classification:

Â· Compute continuous scores for Insight/Frustration/Illusion
Â· Assign primary outcome (highest score)
Â· Check distribution (expect ~30-40% per category based on pilot)

---

Primary Analyses:

Analysis 1: Multinomial Logistic Regression

Model:

```r
library(nnet)

model <- multinom(R_outcome ~ N + W + S + M_composite + 
                  N:W + W:S + S:M, 
                  data = data)
```

Primary Test: Effect of N, W, S, M on probability of each outcome (Insight vs Frustration vs Illusion)

Covariates: Age, gender, AI experience (if significant in preliminary checks)

Effect Sizes: Odds ratios (OR) and 95% CIs

---

Analysis 2: Latent Profile Analysis (LPA)

Rationale: Identify naturally occurring user "profiles" based on N/W/S

Model:

```r
library(tidyLPA)

profiles <- estimate_profiles(data[, c("N", "W", "S")], 
                               n_profiles = 2:5)
```

Steps:

1. Determine optimal number of profiles (BIC, entropy)
2. Characterize each profile (e.g., "Critical Skeptic", "Naive Seeker", "Contemplative Explorer")
3. Test: Profile â†’ R outcome (chi-square or multinomial regression)

---

Analysis 3: Moderation Analysis

Test H4: Does M moderate N/W/S â†’ R relationships?

Model:

```r
# Example for M moderating N â†’ R_insight
glm(R_insight ~ N * M_composite + W + S, 
    family = binomial, data = data)
```

Interpretation: Does deeper engagement (high M) amplify benefits of high N/W/S?

---

Secondary Analyses:

1. Qualitative Coding:

Â· Open-ended responses: thematic analysis
Â· Identify unexpected pathways or experiences
Â· Triangulate with quantitative findings

2. Interaction Log Content Analysis:

Â· What topics do Insight users discuss vs Frustration/Illusion?
Â· Linguistic differences (e.g., question types, pronoun use)
Â· AI response patterns (does AI "style" matter?)

3. Exploratory:

Â· Gender differences in pathways
Â· Age effects (younger â†’ more Illusion?)
Â· Platform differences (ChatGPT vs Claude vs Copilot vs DeepSeek)

---

ðŸ”’ Ethical Considerations

Informed Consent:

Â· Participants informed about:
  Â· Study purpose (understanding AI interaction for self-reflection)
  Â· Data collected (surveys + anonymized conversation log)
  Â· Risks (minimal: potential discomfort reflecting on AI interactions)
  Â· Benefits (contribution to research, self-awareness)
  Â· Right to withdraw anytime

Privacy & Anonymization:

Â· Conversation logs: participants remove all identifying information before upload
Â· Data stored on encrypted servers (Qualtrics/REDCap)
Â· No IP addresses or identifying metadata collected
Â· Data de-identified before analysis

Mental Health Safeguards:

Â· Screener excludes acute mental health crises
Â· Post-study resources provided (crisis hotlines, therapy directories)
Â· If participant reports distress â†’ follow-up contact with resources

Deception:

Â· No deception used
Â· Full disclosure of study purpose after completion

---

âš ï¸ Limitations & Anticipated Challenges

1. Self-Selection Bias:

Â· Users who volunteer may already be more reflective or AI-savvy
Â· Mitigation: Stratified recruitment, document demographics

2. Self-Report for Outcome:

Â· R (outcome) is subjective self-report, not objective measure
Â· Mitigation: Triangulate with qualitative data, use validated scales where possible

3. Single Interaction:

Â· Only captures one AI conversation, not longitudinal patterns
Â· Mitigation: Ask about "typical" experience, future studies can track over time

4. Platform Variability:

Â· Different AIs (ChatGPT, Claude, Copilot, DeepSeek, etc.) may produce different experiences
Â· Mitigation: Collect platform data, control in analysis if needed

5. Causality:

Â· Cross-sectional design cannot establish causation (N/W/S â†’ R vs R â†’ N/W/S)
Â· Mitigation: Pre-post design (N/W/S before, R after) provides temporal ordering

6. Measurement Validity:

Â· Custom scales (N, W, R) not yet fully validated
Â· Mitigation: Pilot test, report psychometric properties, revise if needed

---

ðŸ“š Theoretical & Practical Contributions

Theoretical:

1. First empirical test of psychological predictors of AI-mediated self-discovery outcomes
2. Integrates mindfulness theory, critical AI literacy, and human-AI interaction research
3. Challenges assumptions that AI is universally beneficial or harmful for self-reflection
4. Proposes R = f(N,W,S,M) as a generalizable framework for AI interaction quality

---

Practical:

1. Informs AI design: How to support insight pathways, prevent illusion
2. User guidance: Develop "best practices" for self-reflective AI use
3. Education: Teach critical AI literacy (W) and contemplative skills (S)
4. Therapeutic applications: Guidelines for AI-assisted self-reflection in clinical contexts

---

ðŸ“– References (Key)

Human-AI Interaction:

Â· Cowan, B. R., et al. (2023). Understanding trust in conversational agents. CHI.
Â· Sundar, S. S. (2020). Rise of machine agency. Journal of Computer-Mediated Communication.

Critical AI Literacy:

Â· Long, D., & Magerko, B. (2020). What is AI literacy? CHI.
Â· Druga, S., et al. (2022). How young children understand AI. IDC.

Mindfulness & Self-Reflection:

Â· Laukkonen, R. E., et al. (2022). The science of insight. Psychological Bulletin.
Â· Killingsworth, M. A., & Gilbert, D. T. (2010). A wandering mind is an unhappy mind. Science.

AI for Self-Discovery:

Â· Pataranutaporn, P., et al. (2021). AI-mediated communication. Extended Abstracts CHI.
Â· Inkster, B., et al. (2023). Digital mental health. Nature Digital Medicine.

---

ðŸ“§ Contact & Transparency

Principal Investigator:
Samir Baladi
Email: riteofrenaissance@proton.me

Pre-registration:
[To be registered on OSF before data collection]

Open Science Commitment:

Â· âœ… Pre-registration (this protocol)
Â· âœ… Open materials (all scales publicly shared)
Â· âœ… Open data (de-identified dataset after publication)
Â· âœ… Open code (R analysis scripts)

---

ðŸ“ Version History

Version Date Changes
1.0 April 2026 Initial protocol for pre-registration

---

Document Status: Draft for pre-registration
Next Step: IRB submission (June 2026)
